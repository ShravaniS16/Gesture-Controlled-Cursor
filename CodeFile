import cv2
import mediapipe as mp
import pyautogui
import numpy as np
import time

# Initialize MediaPipe Hands
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mp_drawing = mp.solutions.drawing_utils

# Start video capture
cap = cv2.VideoCapture(0)  # Use 0 for the default camera
if not cap.isOpened():
    print("Error: Could not open video.")
    exit()

# Constants for screen size
SCREEN_WIDTH, SCREEN_HEIGHT = pyautogui.size()

# Function to get landmark position
def get_landmark_position(landmarks, index):
    x = landmarks.landmark[index].x
    y = landmarks.landmark[index].y
    return x, y

# Variables for click detection
last_click_time = 0
click_delay = 0.5  # Delay to prevent multiple clicks
distance_threshold = 0.05  # Adjust as needed for click detection

# Function to calculate the position of the cursor smoothly
def smooth_move_to(x, y, duration=0.1):
    current_x, current_y = pyautogui.position()
    for i in range(1, 11):
        pyautogui.moveTo(current_x + (x - current_x) * i / 10, current_y + (y - current_y) * i / 10)
        time.sleep(duration / 10)

try:
    while True:
        success, image = cap.read()
        if not success:
            print("Error: Could not read frame.")
            break

        # Flip the image horizontally
        image = cv2.flip(image, 1)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        result = hands.process(image_rgb)

        if result.multi_hand_landmarks:
            for hand_landmarks in result.multi_hand_landmarks:
                # Get index finger tip position and thumb tip position
                index_finger_x, index_finger_y = get_landmark_position(hand_landmarks, 8)
                thumb_x, thumb_y = get_landmark_position(hand_landmarks, 4)

                # Move mouse cursor based on index finger tip
                screen_x = np.interp(index_finger_x, [0, 1], [0, SCREEN_WIDTH])
                screen_y = np.interp(index_finger_y, [0, 1], [0, SCREEN_HEIGHT])
                smooth_move_to(screen_x, screen_y)

                # Calculate distance between index finger and thumb for clicking
                distance = np.sqrt((index_finger_x - thumb_x) ** 2 + (index_finger_y - thumb_y) ** 2)

                # Check for click gesture (pinch)
                if distance < distance_threshold:  # Adjust threshold as needed
                    current_time = time.time()
                    if current_time - last_click_time > click_delay:  # Prevent multiple clicks
                        pyautogui.click()  # Perform a mouse click
                        last_click_time = current_time

                        # Visual feedback on click
                        cv2.circle(image, (int(screen_x), int(screen_y)), 10, (0, 255, 0), -1)  # Green circle

                # Draw the hand landmarks on the image
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

        # Show the image with hand landmarks
        cv2.imshow("Gesture Control", image)

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("Process interrupted by user.")

finally:
    cap.release()
    cv2.destroyAllWindows()
